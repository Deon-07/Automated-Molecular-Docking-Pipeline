#!/bin/bash

# =============================================================================
# Slurm Job Script Generator for AutoDock Vina Pipeline
# =============================================================================
# Generates .sbatch files for HPC cluster submission
# Usage: ./generate_slurm.sh -c docking.conf -o my_job.sbatch
# =============================================================================

show_help() {
    cat << EOF
Slurm Job Script Generator for AutoDock Vina Pipeline

Usage: $0 [OPTIONS]

Options:
  -c FILE     Config file to use (required)
  -o FILE     Output .sbatch file (default: docking_job.sbatch)
  -p PART     Partition/queue name (default: batch)
  -t TIME     Time limit (default: 24:00:00)
  -m MEM      Memory allocation (default: 16G)
  -h          Show this help

Example:
  $0 -c docking.conf -o my_screening.sbatch -p gpu -t 48:00:00
EOF
    exit 0
}

# Defaults
CONFIG_FILE=""
OUTPUT_FILE="docking_job.sbatch"
PARTITION="batch"
TIME_LIMIT="24:00:00"
MEMORY="16G"

# Parse arguments
while getopts "c:o:p:t:m:h" opt; do
    case $opt in
        c) CONFIG_FILE="$OPTARG" ;;
        o) OUTPUT_FILE="$OPTARG" ;;
        p) PARTITION="$OPTARG" ;;
        t) TIME_LIMIT="$OPTARG" ;;
        m) MEMORY="$OPTARG" ;;
        h) show_help ;;
        \?) echo "Invalid option: -$OPTARG" >&2; show_help ;;
    esac
done

# Validate config file
if [ -z "$CONFIG_FILE" ]; then
    echo "ERROR: Config file is required. Use -c to specify."
    show_help
fi

if [ ! -f "$CONFIG_FILE" ]; then
    echo "ERROR: Config file not found: $CONFIG_FILE"
    exit 1
fi

# Source config to get variables
source "$CONFIG_FILE"

# Calculate total CPUs
CONCURRENT_JOBS="${CONCURRENT_JOBS:-4}"
THREADS_PER_JOB="${THREADS_PER_JOB:-2}"
TOTAL_CPUS=$((CONCURRENT_JOBS * THREADS_PER_JOB))

# Extract job name from receptor file
RECEPTOR_PDB_FILE="${RECEPTOR_PDB_FILE:-receptor.pdb}"
JOB_NAME="dock_$(basename "$RECEPTOR_PDB_FILE" .pdb)"

# Determine GPU requirements
GPU_DIRECTIVE=""
if [ "${USE_GPU:-false}" = "true" ]; then
    GPU_DIRECTIVE="#SBATCH --gres=gpu:1"
    PARTITION="gpu"  # Override to GPU partition
fi

# Get absolute path to config file
ABS_CONFIG=$(realpath "$CONFIG_FILE")

# Generate sbatch file
cat > "$OUTPUT_FILE" << EOF
#!/bin/bash
#SBATCH --job-name=${JOB_NAME}
#SBATCH --partition=${PARTITION}
#SBATCH --cpus-per-task=${TOTAL_CPUS}
#SBATCH --mem=${MEMORY}
#SBATCH --time=${TIME_LIMIT}
#SBATCH --output=docking_%j.log
#SBATCH --error=docking_%j.err
${GPU_DIRECTIVE}

# =============================================================================
# AutoDock Vina Docking Job
# Generated by generate_slurm.sh
# Config: ${ABS_CONFIG}
# =============================================================================

echo "Job started: \$(date)"
echo "Running on: \$(hostname)"
echo "CPUs allocated: \$SLURM_CPUS_PER_TASK"

# Load required modules (customize for your cluster)
# module load openbabel
# module load autodock-vina
# module load cuda  # If using GPU

# Run the docking pipeline
./Auto-dock.sh -c "${ABS_CONFIG}"

echo "Job completed: \$(date)"
EOF

chmod +x "$OUTPUT_FILE"

echo "Generated Slurm script: $OUTPUT_FILE"
echo "  Job Name: $JOB_NAME"
echo "  CPUs: $TOTAL_CPUS ($CONCURRENT_JOBS jobs Ã— $THREADS_PER_JOB threads)"
echo "  Memory: $MEMORY"
echo "  Time: $TIME_LIMIT"
echo "  Partition: $PARTITION"
if [ -n "$GPU_DIRECTIVE" ]; then
    echo "  GPU: Enabled (1 GPU requested)"
fi
echo ""
echo "Submit with: sbatch $OUTPUT_FILE"
